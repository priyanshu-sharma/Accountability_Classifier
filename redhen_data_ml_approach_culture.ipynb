{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.nlp import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>StoryID</th>\n",
       "      <th>Excerpt</th>\n",
       "      <th>CodesApplied_Combined</th>\n",
       "      <th>ACCOUNT</th>\n",
       "      <th>ACCOUNT_Cultural</th>\n",
       "      <th>ACCOUNT_Individual</th>\n",
       "      <th>ACCOUNT_Other</th>\n",
       "      <th>COMMUNITYRECOVERY</th>\n",
       "      <th>EVENT</th>\n",
       "      <th>...</th>\n",
       "      <th>TRAUMA_Societal</th>\n",
       "      <th>VICTIMS</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>Excerpt_pre</th>\n",
       "      <th>Excerpt_tokenized</th>\n",
       "      <th>Excerpt_nonstop</th>\n",
       "      <th>Excerpt_stemmed</th>\n",
       "      <th>Excerpt_lemmatized</th>\n",
       "      <th>Excerpt_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7992</td>\n",
       "      <td>NI3079</td>\n",
       "      <td>Elliot Rodger Wangs roommate stabbed Wang and ...</td>\n",
       "      <td>EVENT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>215.0</td>\n",
       "      <td>elliot rodger wangs roommate stabbed wang two ...</td>\n",
       "      <td>['elliot', 'rodger', 'wangs', 'roommate', 'sta...</td>\n",
       "      <td>['elliot', 'rodger', 'wangs', 'roommate', 'sta...</td>\n",
       "      <td>['elliot', 'rodger', 'wang', 'roommat', 'stab'...</td>\n",
       "      <td>['elliot', 'rodger', 'wangs', 'roommate', 'sta...</td>\n",
       "      <td>['elliot', 'rodger', 'wang', 'roommat', 'stab'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4686</td>\n",
       "      <td>NI2689</td>\n",
       "      <td>Because the tragedy unfolded at the start of a...</td>\n",
       "      <td>RESOURCES</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>228.0</td>\n",
       "      <td>tragedy unfolded start holiday weekend school ...</td>\n",
       "      <td>['tragedy', 'unfolded', 'start', 'holiday', 'w...</td>\n",
       "      <td>['tragedy', 'unfolded', 'start', 'holiday', 'w...</td>\n",
       "      <td>['tragedi', 'unfold', 'start', 'holiday', 'wee...</td>\n",
       "      <td>['tragedy', 'unfolded', 'start', 'holiday', 'w...</td>\n",
       "      <td>['tragedi', 'unfold', 'start', 'holiday', 'wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6130</td>\n",
       "      <td>NI2400</td>\n",
       "      <td>Gunrelated restraining orders Also passed in r...</td>\n",
       "      <td>POLICY, POLICY- Guns, POLICY- Mental health</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>734.0</td>\n",
       "      <td>gunrelated restraining orders also passed resp...</td>\n",
       "      <td>['gunrelated', 'restraining', 'orders', 'also'...</td>\n",
       "      <td>['gunrelated', 'restraining', 'orders', 'also'...</td>\n",
       "      <td>['gunrel', 'restrain', 'order', 'also', 'pass'...</td>\n",
       "      <td>['gunrelated', 'restraining', 'order', 'also',...</td>\n",
       "      <td>['gunrel', 'restrain', 'order', 'also', 'pass'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5876</td>\n",
       "      <td>NI1393</td>\n",
       "      <td>Linder said she will also remember Weiss for h...</td>\n",
       "      <td>VICTIMS, GRIEF/LOSS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>499.0</td>\n",
       "      <td>linder said also remember weiss epic shot pool...</td>\n",
       "      <td>['linder', 'said', 'also', 'remember', 'weiss'...</td>\n",
       "      <td>['linder', 'said', 'also', 'remember', 'weiss'...</td>\n",
       "      <td>['linder', 'said', 'also', 'rememb', 'weiss', ...</td>\n",
       "      <td>['linder', 'said', 'also', 'remember', 'wei', ...</td>\n",
       "      <td>['linder', 'said', 'also', 'rememb', 'weiss', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4126</td>\n",
       "      <td>NI3259</td>\n",
       "      <td>I mean I know how this goes We all do Werent y...</td>\n",
       "      <td>ACCOUNTABILITY, ACCOUNT- Culture/societal risk...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>425.0</td>\n",
       "      <td>mean know goes werent sort expecting father on...</td>\n",
       "      <td>['mean', 'know', 'goes', 'werent', 'sort', 'ex...</td>\n",
       "      <td>['mean', 'know', 'goes', 'werent', 'sort', 'ex...</td>\n",
       "      <td>['mean', 'know', 'goe', 'werent', 'sort', 'exp...</td>\n",
       "      <td>['mean', 'know', 'go', 'werent', 'sort', 'expe...</td>\n",
       "      <td>['mean', 'know', 'goe', 'werent', 'sort', 'exp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 StoryID                                            Excerpt  \\\n",
       "0        7992  NI3079  Elliot Rodger Wangs roommate stabbed Wang and ...   \n",
       "1        4686  NI2689  Because the tragedy unfolded at the start of a...   \n",
       "2        6130  NI2400  Gunrelated restraining orders Also passed in r...   \n",
       "3        5876  NI1393  Linder said she will also remember Weiss for h...   \n",
       "4        4126  NI3259  I mean I know how this goes We all do Werent y...   \n",
       "\n",
       "                               CodesApplied_Combined  ACCOUNT  \\\n",
       "0                                              EVENT        0   \n",
       "1                                          RESOURCES        0   \n",
       "2        POLICY, POLICY- Guns, POLICY- Mental health        0   \n",
       "3                                VICTIMS, GRIEF/LOSS        0   \n",
       "4  ACCOUNTABILITY, ACCOUNT- Culture/societal risk...        1   \n",
       "\n",
       "   ACCOUNT_Cultural  ACCOUNT_Individual  ACCOUNT_Other  COMMUNITYRECOVERY  \\\n",
       "0                 0                   0              0                 99   \n",
       "1                 0                   0              0                 99   \n",
       "2                 0                   0              0                 99   \n",
       "3                 0                   0              0                 99   \n",
       "4                 1                   0              0                 99   \n",
       "\n",
       "   EVENT  ...  TRAUMA_Societal  VICTIMS  word_count  char_count  \\\n",
       "0      1  ...               99        0          34       215.0   \n",
       "1      0  ...               99        0          32       228.0   \n",
       "2      0  ...               99        0         122       734.0   \n",
       "3      0  ...               99        1         100       499.0   \n",
       "4      0  ...               99        0          85       425.0   \n",
       "\n",
       "                                         Excerpt_pre  \\\n",
       "0  elliot rodger wangs roommate stabbed wang two ...   \n",
       "1  tragedy unfolded start holiday weekend school ...   \n",
       "2  gunrelated restraining orders also passed resp...   \n",
       "3  linder said also remember weiss epic shot pool...   \n",
       "4  mean know goes werent sort expecting father on...   \n",
       "\n",
       "                                   Excerpt_tokenized  \\\n",
       "0  ['elliot', 'rodger', 'wangs', 'roommate', 'sta...   \n",
       "1  ['tragedy', 'unfolded', 'start', 'holiday', 'w...   \n",
       "2  ['gunrelated', 'restraining', 'orders', 'also'...   \n",
       "3  ['linder', 'said', 'also', 'remember', 'weiss'...   \n",
       "4  ['mean', 'know', 'goes', 'werent', 'sort', 'ex...   \n",
       "\n",
       "                                     Excerpt_nonstop  \\\n",
       "0  ['elliot', 'rodger', 'wangs', 'roommate', 'sta...   \n",
       "1  ['tragedy', 'unfolded', 'start', 'holiday', 'w...   \n",
       "2  ['gunrelated', 'restraining', 'orders', 'also'...   \n",
       "3  ['linder', 'said', 'also', 'remember', 'weiss'...   \n",
       "4  ['mean', 'know', 'goes', 'werent', 'sort', 'ex...   \n",
       "\n",
       "                                     Excerpt_stemmed  \\\n",
       "0  ['elliot', 'rodger', 'wang', 'roommat', 'stab'...   \n",
       "1  ['tragedi', 'unfold', 'start', 'holiday', 'wee...   \n",
       "2  ['gunrel', 'restrain', 'order', 'also', 'pass'...   \n",
       "3  ['linder', 'said', 'also', 'rememb', 'weiss', ...   \n",
       "4  ['mean', 'know', 'goe', 'werent', 'sort', 'exp...   \n",
       "\n",
       "                                  Excerpt_lemmatized  \\\n",
       "0  ['elliot', 'rodger', 'wangs', 'roommate', 'sta...   \n",
       "1  ['tragedy', 'unfolded', 'start', 'holiday', 'w...   \n",
       "2  ['gunrelated', 'restraining', 'order', 'also',...   \n",
       "3  ['linder', 'said', 'also', 'remember', 'wei', ...   \n",
       "4  ['mean', 'know', 'go', 'werent', 'sort', 'expe...   \n",
       "\n",
       "                                       Excerpt_clean  \n",
       "0  ['elliot', 'rodger', 'wang', 'roommat', 'stab'...  \n",
       "1  ['tragedi', 'unfold', 'start', 'holiday', 'wee...  \n",
       "2  ['gunrel', 'restrain', 'order', 'also', 'pass'...  \n",
       "3  ['linder', 'said', 'also', 'rememb', 'weiss', ...  \n",
       "4  ['mean', 'know', 'goe', 'werent', 'sort', 'exp...  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('redhen_preprocessed.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8131, 62)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'StoryID', 'Excerpt', 'CodesApplied_Combined', 'ACCOUNT',\n",
       "       'ACCOUNT_Cultural', 'ACCOUNT_Individual', 'ACCOUNT_Other',\n",
       "       'COMMUNITYRECOVERY', 'EVENT', 'GRIEF', 'GRIEF_Individual',\n",
       "       'GRIEF_Community', 'GRIEF_Societal', 'HERO', 'INVESTIGATION', 'JOURNEY',\n",
       "       'JOURNEY_Mental', 'JOURNEY_Physical', 'LEGAL', 'MEDIA', 'MISCELLANEOUS',\n",
       "       'MOURNING', 'MOURNING_Individual', 'MOURNING_Community',\n",
       "       'MOURNING_Societal', 'PERPETRATOR', 'PHOTO', 'POLICY', 'POLICY_Guns',\n",
       "       'POLICY_InfoSharing', 'POLICY_MentalHealth', 'POLICY_Other',\n",
       "       'POLICY_VictimAdv', 'POLICY_OtherAdv', 'POLICY_Practice',\n",
       "       'PRIVATESECTOR', 'RACECULTURE', 'RESOURCES', 'SAFETY',\n",
       "       'SAFETY_Community', 'SAFETY_Individual', 'SAFETY_SchoolOrg',\n",
       "       'SAFETY_Societal', 'SOCIALSUPPORT', 'THREAT', 'THREAT_Assessment',\n",
       "       'TRAUMA', 'TRAUMA_Physical', 'TRAUMA_Psychological',\n",
       "       'TRAUMA_Individual', 'TRAUMA_Community', 'TRAUMA_Societal', 'VICTIMS',\n",
       "       'word_count', 'char_count', 'Excerpt_pre', 'Excerpt_tokenized',\n",
       "       'Excerpt_nonstop', 'Excerpt_stemmed', 'Excerpt_lemmatized',\n",
       "       'Excerpt_clean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['StoryID', 'Excerpt', 'Excerpt_pre', 'Excerpt_tokenized',\n",
    "       'Excerpt_nonstop', 'Excerpt_stemmed', 'Excerpt_lemmatized',\n",
    "       'Excerpt_clean', 'ACCOUNT_Cultural']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8131, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StoryID</th>\n",
       "      <th>Excerpt</th>\n",
       "      <th>Excerpt_pre</th>\n",
       "      <th>Excerpt_tokenized</th>\n",
       "      <th>Excerpt_nonstop</th>\n",
       "      <th>Excerpt_stemmed</th>\n",
       "      <th>Excerpt_lemmatized</th>\n",
       "      <th>Excerpt_clean</th>\n",
       "      <th>ACCOUNT_Cultural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NI3079</td>\n",
       "      <td>Elliot Rodger Wangs roommate stabbed Wang and ...</td>\n",
       "      <td>elliot rodger wangs roommate stabbed wang two ...</td>\n",
       "      <td>['elliot', 'rodger', 'wangs', 'roommate', 'sta...</td>\n",
       "      <td>['elliot', 'rodger', 'wangs', 'roommate', 'sta...</td>\n",
       "      <td>['elliot', 'rodger', 'wang', 'roommat', 'stab'...</td>\n",
       "      <td>['elliot', 'rodger', 'wangs', 'roommate', 'sta...</td>\n",
       "      <td>['elliot', 'rodger', 'wang', 'roommat', 'stab'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NI2689</td>\n",
       "      <td>Because the tragedy unfolded at the start of a...</td>\n",
       "      <td>tragedy unfolded start holiday weekend school ...</td>\n",
       "      <td>['tragedy', 'unfolded', 'start', 'holiday', 'w...</td>\n",
       "      <td>['tragedy', 'unfolded', 'start', 'holiday', 'w...</td>\n",
       "      <td>['tragedi', 'unfold', 'start', 'holiday', 'wee...</td>\n",
       "      <td>['tragedy', 'unfolded', 'start', 'holiday', 'w...</td>\n",
       "      <td>['tragedi', 'unfold', 'start', 'holiday', 'wee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NI2400</td>\n",
       "      <td>Gunrelated restraining orders Also passed in r...</td>\n",
       "      <td>gunrelated restraining orders also passed resp...</td>\n",
       "      <td>['gunrelated', 'restraining', 'orders', 'also'...</td>\n",
       "      <td>['gunrelated', 'restraining', 'orders', 'also'...</td>\n",
       "      <td>['gunrel', 'restrain', 'order', 'also', 'pass'...</td>\n",
       "      <td>['gunrelated', 'restraining', 'order', 'also',...</td>\n",
       "      <td>['gunrel', 'restrain', 'order', 'also', 'pass'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NI1393</td>\n",
       "      <td>Linder said she will also remember Weiss for h...</td>\n",
       "      <td>linder said also remember weiss epic shot pool...</td>\n",
       "      <td>['linder', 'said', 'also', 'remember', 'weiss'...</td>\n",
       "      <td>['linder', 'said', 'also', 'remember', 'weiss'...</td>\n",
       "      <td>['linder', 'said', 'also', 'rememb', 'weiss', ...</td>\n",
       "      <td>['linder', 'said', 'also', 'remember', 'wei', ...</td>\n",
       "      <td>['linder', 'said', 'also', 'rememb', 'weiss', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NI3259</td>\n",
       "      <td>I mean I know how this goes We all do Werent y...</td>\n",
       "      <td>mean know goes werent sort expecting father on...</td>\n",
       "      <td>['mean', 'know', 'goes', 'werent', 'sort', 'ex...</td>\n",
       "      <td>['mean', 'know', 'goes', 'werent', 'sort', 'ex...</td>\n",
       "      <td>['mean', 'know', 'goe', 'werent', 'sort', 'exp...</td>\n",
       "      <td>['mean', 'know', 'go', 'werent', 'sort', 'expe...</td>\n",
       "      <td>['mean', 'know', 'goe', 'werent', 'sort', 'exp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StoryID                                            Excerpt  \\\n",
       "0  NI3079  Elliot Rodger Wangs roommate stabbed Wang and ...   \n",
       "1  NI2689  Because the tragedy unfolded at the start of a...   \n",
       "2  NI2400  Gunrelated restraining orders Also passed in r...   \n",
       "3  NI1393  Linder said she will also remember Weiss for h...   \n",
       "4  NI3259  I mean I know how this goes We all do Werent y...   \n",
       "\n",
       "                                         Excerpt_pre  \\\n",
       "0  elliot rodger wangs roommate stabbed wang two ...   \n",
       "1  tragedy unfolded start holiday weekend school ...   \n",
       "2  gunrelated restraining orders also passed resp...   \n",
       "3  linder said also remember weiss epic shot pool...   \n",
       "4  mean know goes werent sort expecting father on...   \n",
       "\n",
       "                                   Excerpt_tokenized  \\\n",
       "0  ['elliot', 'rodger', 'wangs', 'roommate', 'sta...   \n",
       "1  ['tragedy', 'unfolded', 'start', 'holiday', 'w...   \n",
       "2  ['gunrelated', 'restraining', 'orders', 'also'...   \n",
       "3  ['linder', 'said', 'also', 'remember', 'weiss'...   \n",
       "4  ['mean', 'know', 'goes', 'werent', 'sort', 'ex...   \n",
       "\n",
       "                                     Excerpt_nonstop  \\\n",
       "0  ['elliot', 'rodger', 'wangs', 'roommate', 'sta...   \n",
       "1  ['tragedy', 'unfolded', 'start', 'holiday', 'w...   \n",
       "2  ['gunrelated', 'restraining', 'orders', 'also'...   \n",
       "3  ['linder', 'said', 'also', 'remember', 'weiss'...   \n",
       "4  ['mean', 'know', 'goes', 'werent', 'sort', 'ex...   \n",
       "\n",
       "                                     Excerpt_stemmed  \\\n",
       "0  ['elliot', 'rodger', 'wang', 'roommat', 'stab'...   \n",
       "1  ['tragedi', 'unfold', 'start', 'holiday', 'wee...   \n",
       "2  ['gunrel', 'restrain', 'order', 'also', 'pass'...   \n",
       "3  ['linder', 'said', 'also', 'rememb', 'weiss', ...   \n",
       "4  ['mean', 'know', 'goe', 'werent', 'sort', 'exp...   \n",
       "\n",
       "                                  Excerpt_lemmatized  \\\n",
       "0  ['elliot', 'rodger', 'wangs', 'roommate', 'sta...   \n",
       "1  ['tragedy', 'unfolded', 'start', 'holiday', 'w...   \n",
       "2  ['gunrelated', 'restraining', 'order', 'also',...   \n",
       "3  ['linder', 'said', 'also', 'remember', 'wei', ...   \n",
       "4  ['mean', 'know', 'go', 'werent', 'sort', 'expe...   \n",
       "\n",
       "                                       Excerpt_clean  ACCOUNT_Cultural  \n",
       "0  ['elliot', 'rodger', 'wang', 'roommat', 'stab'...                 0  \n",
       "1  ['tragedi', 'unfold', 'start', 'holiday', 'wee...                 0  \n",
       "2  ['gunrel', 'restrain', 'order', 'also', 'pass'...                 0  \n",
       "3  ['linder', 'said', 'also', 'rememb', 'weiss', ...                 0  \n",
       "4  ['mean', 'know', 'goe', 'werent', 'sort', 'exp...                 1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StoryID</th>\n",
       "      <th>Excerpt</th>\n",
       "      <th>Excerpt_pre</th>\n",
       "      <th>Excerpt_tokenized</th>\n",
       "      <th>Excerpt_nonstop</th>\n",
       "      <th>Excerpt_stemmed</th>\n",
       "      <th>Excerpt_lemmatized</th>\n",
       "      <th>Excerpt_clean</th>\n",
       "      <th>ACCOUNT_Cultural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NI3079</td>\n",
       "      <td>Elliot Rodger Wangs roommate stabbed Wang and ...</td>\n",
       "      <td>elliot rodger wangs roommate stabbed wang two ...</td>\n",
       "      <td>['elliot', 'rodger', 'wangs', 'roommate', 'sta...</td>\n",
       "      <td>['elliot', 'rodger', 'wangs', 'roommate', 'sta...</td>\n",
       "      <td>['elliot', 'rodger', 'wang', 'roommat', 'stab'...</td>\n",
       "      <td>['elliot', 'rodger', 'wangs', 'roommate', 'sta...</td>\n",
       "      <td>['elliot', 'rodger', 'wang', 'roommat', 'stab'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NI2689</td>\n",
       "      <td>Because the tragedy unfolded at the start of a...</td>\n",
       "      <td>tragedy unfolded start holiday weekend school ...</td>\n",
       "      <td>['tragedy', 'unfolded', 'start', 'holiday', 'w...</td>\n",
       "      <td>['tragedy', 'unfolded', 'start', 'holiday', 'w...</td>\n",
       "      <td>['tragedi', 'unfold', 'start', 'holiday', 'wee...</td>\n",
       "      <td>['tragedy', 'unfolded', 'start', 'holiday', 'w...</td>\n",
       "      <td>['tragedi', 'unfold', 'start', 'holiday', 'wee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NI2400</td>\n",
       "      <td>Gunrelated restraining orders Also passed in r...</td>\n",
       "      <td>gunrelated restraining orders also passed resp...</td>\n",
       "      <td>['gunrelated', 'restraining', 'orders', 'also'...</td>\n",
       "      <td>['gunrelated', 'restraining', 'orders', 'also'...</td>\n",
       "      <td>['gunrel', 'restrain', 'order', 'also', 'pass'...</td>\n",
       "      <td>['gunrelated', 'restraining', 'order', 'also',...</td>\n",
       "      <td>['gunrel', 'restrain', 'order', 'also', 'pass'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NI1393</td>\n",
       "      <td>Linder said she will also remember Weiss for h...</td>\n",
       "      <td>linder said also remember weiss epic shot pool...</td>\n",
       "      <td>['linder', 'said', 'also', 'remember', 'weiss'...</td>\n",
       "      <td>['linder', 'said', 'also', 'remember', 'weiss'...</td>\n",
       "      <td>['linder', 'said', 'also', 'rememb', 'weiss', ...</td>\n",
       "      <td>['linder', 'said', 'also', 'remember', 'wei', ...</td>\n",
       "      <td>['linder', 'said', 'also', 'rememb', 'weiss', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NI1186</td>\n",
       "      <td>But three days after Cheng Yuan James Hong Ge...</td>\n",
       "      <td>three days cheng yuan james hong george chen w...</td>\n",
       "      <td>['three', 'days', 'cheng', 'yuan', 'james', 'h...</td>\n",
       "      <td>['three', 'days', 'cheng', 'yuan', 'james', 'h...</td>\n",
       "      <td>['three', 'day', 'cheng', 'yuan', 'jame', 'hon...</td>\n",
       "      <td>['three', 'day', 'cheng', 'yuan', 'james', 'ho...</td>\n",
       "      <td>['three', 'day', 'cheng', 'yuan', 'jame', 'hon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StoryID                                            Excerpt  \\\n",
       "0  NI3079  Elliot Rodger Wangs roommate stabbed Wang and ...   \n",
       "1  NI2689  Because the tragedy unfolded at the start of a...   \n",
       "2  NI2400  Gunrelated restraining orders Also passed in r...   \n",
       "3  NI1393  Linder said she will also remember Weiss for h...   \n",
       "5  NI1186   But three days after Cheng Yuan James Hong Ge...   \n",
       "\n",
       "                                         Excerpt_pre  \\\n",
       "0  elliot rodger wangs roommate stabbed wang two ...   \n",
       "1  tragedy unfolded start holiday weekend school ...   \n",
       "2  gunrelated restraining orders also passed resp...   \n",
       "3  linder said also remember weiss epic shot pool...   \n",
       "5  three days cheng yuan james hong george chen w...   \n",
       "\n",
       "                                   Excerpt_tokenized  \\\n",
       "0  ['elliot', 'rodger', 'wangs', 'roommate', 'sta...   \n",
       "1  ['tragedy', 'unfolded', 'start', 'holiday', 'w...   \n",
       "2  ['gunrelated', 'restraining', 'orders', 'also'...   \n",
       "3  ['linder', 'said', 'also', 'remember', 'weiss'...   \n",
       "5  ['three', 'days', 'cheng', 'yuan', 'james', 'h...   \n",
       "\n",
       "                                     Excerpt_nonstop  \\\n",
       "0  ['elliot', 'rodger', 'wangs', 'roommate', 'sta...   \n",
       "1  ['tragedy', 'unfolded', 'start', 'holiday', 'w...   \n",
       "2  ['gunrelated', 'restraining', 'orders', 'also'...   \n",
       "3  ['linder', 'said', 'also', 'remember', 'weiss'...   \n",
       "5  ['three', 'days', 'cheng', 'yuan', 'james', 'h...   \n",
       "\n",
       "                                     Excerpt_stemmed  \\\n",
       "0  ['elliot', 'rodger', 'wang', 'roommat', 'stab'...   \n",
       "1  ['tragedi', 'unfold', 'start', 'holiday', 'wee...   \n",
       "2  ['gunrel', 'restrain', 'order', 'also', 'pass'...   \n",
       "3  ['linder', 'said', 'also', 'rememb', 'weiss', ...   \n",
       "5  ['three', 'day', 'cheng', 'yuan', 'jame', 'hon...   \n",
       "\n",
       "                                  Excerpt_lemmatized  \\\n",
       "0  ['elliot', 'rodger', 'wangs', 'roommate', 'sta...   \n",
       "1  ['tragedy', 'unfolded', 'start', 'holiday', 'w...   \n",
       "2  ['gunrelated', 'restraining', 'order', 'also',...   \n",
       "3  ['linder', 'said', 'also', 'remember', 'wei', ...   \n",
       "5  ['three', 'day', 'cheng', 'yuan', 'james', 'ho...   \n",
       "\n",
       "                                       Excerpt_clean  ACCOUNT_Cultural  \n",
       "0  ['elliot', 'rodger', 'wang', 'roommat', 'stab'...                 0  \n",
       "1  ['tragedi', 'unfold', 'start', 'holiday', 'wee...                 0  \n",
       "2  ['gunrel', 'restrain', 'order', 'also', 'pass'...                 0  \n",
       "3  ['linder', 'said', 'also', 'rememb', 'weiss', ...                 0  \n",
       "5  ['three', 'day', 'cheng', 'yuan', 'jame', 'hon...                 0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_uncl = data.loc[data['ACCOUNT_Cultural']==0]\n",
    "data_uncl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_uncl.ACCOUNT_Cultural.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6978, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_uncl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1153, 9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cl = data.loc[data['ACCOUNT_Cultural']==1]\n",
    "data_cl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1153, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_uncl = data_uncl.sample(1153)\n",
    "data_uncl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1153, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_uncl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StoryID</th>\n",
       "      <th>Excerpt</th>\n",
       "      <th>Excerpt_pre</th>\n",
       "      <th>Excerpt_tokenized</th>\n",
       "      <th>Excerpt_nonstop</th>\n",
       "      <th>Excerpt_stemmed</th>\n",
       "      <th>Excerpt_lemmatized</th>\n",
       "      <th>Excerpt_clean</th>\n",
       "      <th>ACCOUNT_Cultural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NI3259</td>\n",
       "      <td>I mean I know how this goes We all do Werent y...</td>\n",
       "      <td>mean know goes werent sort expecting father on...</td>\n",
       "      <td>['mean', 'know', 'goes', 'werent', 'sort', 'ex...</td>\n",
       "      <td>['mean', 'know', 'goes', 'werent', 'sort', 'ex...</td>\n",
       "      <td>['mean', 'know', 'goe', 'werent', 'sort', 'exp...</td>\n",
       "      <td>['mean', 'know', 'go', 'werent', 'sort', 'expe...</td>\n",
       "      <td>['mean', 'know', 'goe', 'werent', 'sort', 'exp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NI1111</td>\n",
       "      <td>At the earlier press conference Martinez shook...</td>\n",
       "      <td>earlier press conference martinez shook visibl...</td>\n",
       "      <td>['earlier', 'press', 'conference', 'martinez',...</td>\n",
       "      <td>['earlier', 'press', 'conference', 'martinez',...</td>\n",
       "      <td>['earlier', 'press', 'confer', 'martinez', 'sh...</td>\n",
       "      <td>['earlier', 'press', 'conference', 'martinez',...</td>\n",
       "      <td>['earlier', 'press', 'confer', 'martinez', 'sh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NI3229</td>\n",
       "      <td>Shall I observe that a gun is a weapon of mass...</td>\n",
       "      <td>shall observe gun weapon mass destruction ment...</td>\n",
       "      <td>['shall', 'observe', 'gun', 'weapon', 'mass', ...</td>\n",
       "      <td>['shall', 'observe', 'gun', 'weapon', 'mass', ...</td>\n",
       "      <td>['shall', 'observ', 'gun', 'weapon', 'mass', '...</td>\n",
       "      <td>['shall', 'observe', 'gun', 'weapon', 'mass', ...</td>\n",
       "      <td>['shall', 'observ', 'gun', 'weapon', 'mass', '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NI2075</td>\n",
       "      <td>At the earlier press conference Martinez shook...</td>\n",
       "      <td>earlier press conference martinez shook visibl...</td>\n",
       "      <td>['earlier', 'press', 'conference', 'martinez',...</td>\n",
       "      <td>['earlier', 'press', 'conference', 'martinez',...</td>\n",
       "      <td>['earlier', 'press', 'confer', 'martinez', 'sh...</td>\n",
       "      <td>['earlier', 'press', 'conference', 'martinez',...</td>\n",
       "      <td>['earlier', 'press', 'confer', 'martinez', 'sh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NI2719</td>\n",
       "      <td>Before the killings Rodgers mother became alar...</td>\n",
       "      <td>killings rodgers mother became alarmed bizarre...</td>\n",
       "      <td>['killings', 'rodgers', 'mother', 'became', 'a...</td>\n",
       "      <td>['killings', 'rodgers', 'mother', 'became', 'a...</td>\n",
       "      <td>['kill', 'rodger', 'mother', 'becam', 'alarm',...</td>\n",
       "      <td>['killing', 'rodgers', 'mother', 'became', 'al...</td>\n",
       "      <td>['kill', 'rodger', 'mother', 'becam', 'alarm',...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   StoryID                                            Excerpt  \\\n",
       "4   NI3259  I mean I know how this goes We all do Werent y...   \n",
       "19  NI1111  At the earlier press conference Martinez shook...   \n",
       "30  NI3229  Shall I observe that a gun is a weapon of mass...   \n",
       "36  NI2075  At the earlier press conference Martinez shook...   \n",
       "43  NI2719  Before the killings Rodgers mother became alar...   \n",
       "\n",
       "                                          Excerpt_pre  \\\n",
       "4   mean know goes werent sort expecting father on...   \n",
       "19  earlier press conference martinez shook visibl...   \n",
       "30  shall observe gun weapon mass destruction ment...   \n",
       "36  earlier press conference martinez shook visibl...   \n",
       "43  killings rodgers mother became alarmed bizarre...   \n",
       "\n",
       "                                    Excerpt_tokenized  \\\n",
       "4   ['mean', 'know', 'goes', 'werent', 'sort', 'ex...   \n",
       "19  ['earlier', 'press', 'conference', 'martinez',...   \n",
       "30  ['shall', 'observe', 'gun', 'weapon', 'mass', ...   \n",
       "36  ['earlier', 'press', 'conference', 'martinez',...   \n",
       "43  ['killings', 'rodgers', 'mother', 'became', 'a...   \n",
       "\n",
       "                                      Excerpt_nonstop  \\\n",
       "4   ['mean', 'know', 'goes', 'werent', 'sort', 'ex...   \n",
       "19  ['earlier', 'press', 'conference', 'martinez',...   \n",
       "30  ['shall', 'observe', 'gun', 'weapon', 'mass', ...   \n",
       "36  ['earlier', 'press', 'conference', 'martinez',...   \n",
       "43  ['killings', 'rodgers', 'mother', 'became', 'a...   \n",
       "\n",
       "                                      Excerpt_stemmed  \\\n",
       "4   ['mean', 'know', 'goe', 'werent', 'sort', 'exp...   \n",
       "19  ['earlier', 'press', 'confer', 'martinez', 'sh...   \n",
       "30  ['shall', 'observ', 'gun', 'weapon', 'mass', '...   \n",
       "36  ['earlier', 'press', 'confer', 'martinez', 'sh...   \n",
       "43  ['kill', 'rodger', 'mother', 'becam', 'alarm',...   \n",
       "\n",
       "                                   Excerpt_lemmatized  \\\n",
       "4   ['mean', 'know', 'go', 'werent', 'sort', 'expe...   \n",
       "19  ['earlier', 'press', 'conference', 'martinez',...   \n",
       "30  ['shall', 'observe', 'gun', 'weapon', 'mass', ...   \n",
       "36  ['earlier', 'press', 'conference', 'martinez',...   \n",
       "43  ['killing', 'rodgers', 'mother', 'became', 'al...   \n",
       "\n",
       "                                        Excerpt_clean  ACCOUNT_Cultural  \n",
       "4   ['mean', 'know', 'goe', 'werent', 'sort', 'exp...                 1  \n",
       "19  ['earlier', 'press', 'confer', 'martinez', 'sh...                 1  \n",
       "30  ['shall', 'observ', 'gun', 'weapon', 'mass', '...                 1  \n",
       "36  ['earlier', 'press', 'confer', 'martinez', 'sh...                 1  \n",
       "43  ['kill', 'rodger', 'mother', 'becam', 'alarm',...                 1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cl.ACCOUNT_Cultural.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2306, 9)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = [data_uncl, data_cl]\n",
    "data = pd.concat(dataframe)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Excerpt'].fillna(\"unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StoryID</th>\n",
       "      <th>Excerpt</th>\n",
       "      <th>Excerpt_pre</th>\n",
       "      <th>Excerpt_tokenized</th>\n",
       "      <th>Excerpt_nonstop</th>\n",
       "      <th>Excerpt_stemmed</th>\n",
       "      <th>Excerpt_lemmatized</th>\n",
       "      <th>Excerpt_clean</th>\n",
       "      <th>ACCOUNT_Cultural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7899</th>\n",
       "      <td>NI2612</td>\n",
       "      <td>Hackworth also touched on Coopers worldliness ...</td>\n",
       "      <td>hackworth also touched coopers worldliness sta...</td>\n",
       "      <td>['hackworth', 'also', 'touched', 'coopers', 'w...</td>\n",
       "      <td>['hackworth', 'also', 'touched', 'coopers', 'w...</td>\n",
       "      <td>['hackworth', 'also', 'touch', 'cooper', 'worl...</td>\n",
       "      <td>['hackworth', 'also', 'touched', 'cooper', 'wo...</td>\n",
       "      <td>['hackworth', 'also', 'touch', 'cooper', 'worl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>NI2941</td>\n",
       "      <td>Something is certainly rotten After the Sandy ...</td>\n",
       "      <td>something certainly rotten sandy hook massacre...</td>\n",
       "      <td>['something', 'certainly', 'rotten', 'sandy', ...</td>\n",
       "      <td>['something', 'certainly', 'rotten', 'sandy', ...</td>\n",
       "      <td>['someth', 'certainli', 'rotten', 'sandi', 'ho...</td>\n",
       "      <td>['something', 'certainly', 'rotten', 'sandy', ...</td>\n",
       "      <td>['someth', 'certainli', 'rotten', 'sandi', 'ho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>NI2586</td>\n",
       "      <td>The parents of the first three victims of Elli...</td>\n",
       "      <td>parents first three victims elliot rodgers mur...</td>\n",
       "      <td>['parents', 'first', 'three', 'victims', 'elli...</td>\n",
       "      <td>['parents', 'first', 'three', 'victims', 'elli...</td>\n",
       "      <td>['parent', 'first', 'three', 'victim', 'elliot...</td>\n",
       "      <td>['parent', 'first', 'three', 'victim', 'elliot...</td>\n",
       "      <td>['parent', 'first', 'three', 'victim', 'elliot...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4313</th>\n",
       "      <td>NI2031</td>\n",
       "      <td>Police say Rodger killed six people  stabbing ...</td>\n",
       "      <td>police say rodger killed six people stabbing t...</td>\n",
       "      <td>['police', 'say', 'rodger', 'killed', 'six', '...</td>\n",
       "      <td>['police', 'say', 'rodger', 'killed', 'six', '...</td>\n",
       "      <td>['polic', 'say', 'rodger', 'kill', 'six', 'peo...</td>\n",
       "      <td>['police', 'say', 'rodger', 'killed', 'six', '...</td>\n",
       "      <td>['polic', 'say', 'rodger', 'kill', 'six', 'peo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5043</th>\n",
       "      <td>NI2663</td>\n",
       "      <td>The relative shared other memories of Hong suc...</td>\n",
       "      <td>relative shared memories hong taking vegetaria...</td>\n",
       "      <td>['relative', 'shared', 'memories', 'hong', 'ta...</td>\n",
       "      <td>['relative', 'shared', 'memories', 'hong', 'ta...</td>\n",
       "      <td>['rel', 'share', 'memori', 'hong', 'take', 've...</td>\n",
       "      <td>['relative', 'shared', 'memory', 'hong', 'taki...</td>\n",
       "      <td>['rel', 'share', 'memori', 'hong', 'take', 've...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     StoryID                                            Excerpt  \\\n",
       "7899  NI2612  Hackworth also touched on Coopers worldliness ...   \n",
       "2271  NI2941  Something is certainly rotten After the Sandy ...   \n",
       "2742  NI2586  The parents of the first three victims of Elli...   \n",
       "4313  NI2031  Police say Rodger killed six people  stabbing ...   \n",
       "5043  NI2663  The relative shared other memories of Hong suc...   \n",
       "\n",
       "                                            Excerpt_pre  \\\n",
       "7899  hackworth also touched coopers worldliness sta...   \n",
       "2271  something certainly rotten sandy hook massacre...   \n",
       "2742  parents first three victims elliot rodgers mur...   \n",
       "4313  police say rodger killed six people stabbing t...   \n",
       "5043  relative shared memories hong taking vegetaria...   \n",
       "\n",
       "                                      Excerpt_tokenized  \\\n",
       "7899  ['hackworth', 'also', 'touched', 'coopers', 'w...   \n",
       "2271  ['something', 'certainly', 'rotten', 'sandy', ...   \n",
       "2742  ['parents', 'first', 'three', 'victims', 'elli...   \n",
       "4313  ['police', 'say', 'rodger', 'killed', 'six', '...   \n",
       "5043  ['relative', 'shared', 'memories', 'hong', 'ta...   \n",
       "\n",
       "                                        Excerpt_nonstop  \\\n",
       "7899  ['hackworth', 'also', 'touched', 'coopers', 'w...   \n",
       "2271  ['something', 'certainly', 'rotten', 'sandy', ...   \n",
       "2742  ['parents', 'first', 'three', 'victims', 'elli...   \n",
       "4313  ['police', 'say', 'rodger', 'killed', 'six', '...   \n",
       "5043  ['relative', 'shared', 'memories', 'hong', 'ta...   \n",
       "\n",
       "                                        Excerpt_stemmed  \\\n",
       "7899  ['hackworth', 'also', 'touch', 'cooper', 'worl...   \n",
       "2271  ['someth', 'certainli', 'rotten', 'sandi', 'ho...   \n",
       "2742  ['parent', 'first', 'three', 'victim', 'elliot...   \n",
       "4313  ['polic', 'say', 'rodger', 'kill', 'six', 'peo...   \n",
       "5043  ['rel', 'share', 'memori', 'hong', 'take', 've...   \n",
       "\n",
       "                                     Excerpt_lemmatized  \\\n",
       "7899  ['hackworth', 'also', 'touched', 'cooper', 'wo...   \n",
       "2271  ['something', 'certainly', 'rotten', 'sandy', ...   \n",
       "2742  ['parent', 'first', 'three', 'victim', 'elliot...   \n",
       "4313  ['police', 'say', 'rodger', 'killed', 'six', '...   \n",
       "5043  ['relative', 'shared', 'memory', 'hong', 'taki...   \n",
       "\n",
       "                                          Excerpt_clean  ACCOUNT_Cultural  \n",
       "7899  ['hackworth', 'also', 'touch', 'cooper', 'worl...                 0  \n",
       "2271  ['someth', 'certainli', 'rotten', 'sandi', 'ho...                 1  \n",
       "2742  ['parent', 'first', 'three', 'victim', 'elliot...                 1  \n",
       "4313  ['polic', 'say', 'rodger', 'kill', 'six', 'peo...                 0  \n",
       "5043  ['rel', 'share', 'memori', 'hong', 'take', 've...                 0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "data = shuffle(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ACCOUNT_Cultural.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2306 entries, 7899 to 5849\n",
      "Data columns (total 9 columns):\n",
      "StoryID               2306 non-null object\n",
      "Excerpt               2306 non-null object\n",
      "Excerpt_pre           2306 non-null object\n",
      "Excerpt_tokenized     2306 non-null object\n",
      "Excerpt_nonstop       2306 non-null object\n",
      "Excerpt_stemmed       2306 non-null object\n",
      "Excerpt_lemmatized    2306 non-null object\n",
      "Excerpt_clean         2306 non-null object\n",
      "ACCOUNT_Cultural      2306 non-null int64\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 180.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPLITTING THE DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2306,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data['Excerpt']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7899    Hackworth also touched on Coopers worldliness ...\n",
       "2271    Something is certainly rotten After the Sandy ...\n",
       "2742    The parents of the first three victims of Elli...\n",
       "4313    Police say Rodger killed six people  stabbing ...\n",
       "5043    The relative shared other memories of Hong suc...\n",
       "Name: Excerpt, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['ACCOUNT_Cultural']\n",
    "y = y.to_numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000,), (2000,), (306,), (306,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_vals(a,n): return a[:n].copy(), a[n:].copy()\n",
    "\n",
    "n_valid = 306  \n",
    "n_trn = len(df)-n_valid\n",
    "raw_train, raw_valid = split_vals(data, n_trn)\n",
    "X_train, X_valid = split_vals(df, n_trn)\n",
    "y_train, y_valid = split_vals(y, n_trn)\n",
    "\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7899    Hackworth also touched on Coopers worldliness ...\n",
       "2271    Something is certainly rotten After the Sandy ...\n",
       "2742    The parents of the first three victims of Elli...\n",
       "4313    Police say Rodger killed six people  stabbing ...\n",
       "5043    The relative shared other memories of Hong suc...\n",
       "Name: Excerpt, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2789    Santa Barbara mass shooting suspect Elliot Rod...\n",
       "3756    Authorities do a wellbeing check on Rodger aft...\n",
       "311     Nobody seems to care anymore that its easy for...\n",
       "2286    But what remains unclear is how much police an...\n",
       "7143    Conservative radio host Rush Limbaugh said Tue...\n",
       "Name: Excerpt, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL DEPLOYMENT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer \n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "lem = WordNetLemmatizer()\n",
    "tokenizer=TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_train.shape[0]\n",
    "vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
    "               min_df=3, max_df=0.9, use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1 )\n",
    "trn_term_doc = vec.fit_transform(X_train)\n",
    "test_term_doc = vec.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<2000x18432 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 260527 stored elements in Compressed Sparse Row format>,\n",
       " <306x18432 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 36839 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_term_doc, test_term_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_doc = trn_term_doc\n",
    "val_doc = test_term_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x18432 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 251 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['else obviously',\n",
       " 'else or',\n",
       " 'else rodger',\n",
       " 'else something',\n",
       " 'else the',\n",
       " 'elude',\n",
       " 'elude them',\n",
       " 'email',\n",
       " 'email to',\n",
       " 'emailed']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[5000:5010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAIVE BAYES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x18432 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 260527 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = trn_doc\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y_train\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = x[y==1].sum(0)+1\n",
    "q = x[y==0].sum(0)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1.     , 1.81463, 1.     , ..., 1.98691, 1.58288, 1.58288]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 18432)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[2.4963 , 2.72104, 1.19179, ..., 1.     , 1.     , 1.     ]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 18432)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.log((p/p.sum())/(q/q.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-0.98793, -0.47825, -0.24858, ...,  0.61346,  0.38613,  0.38613]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 18432)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.log(len(p)/len(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(306,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 306)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y = y_valid.reshape(1, 306)\n",
    "val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9084967320261438"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_preds = val_doc @ r.T + b\n",
    "preds = pre_preds.T>0\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9084967320261438"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_preds = val_doc.sign() @ r.T + b\n",
    "preds = pre_preds.T > 0\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x18432 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 260527 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spriyanshu723/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/spriyanshu723/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9117647058823529"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=1e8, dual=True)\n",
    "m.fit(x, y)\n",
    "preds = m.predict(val_doc)\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spriyanshu723/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8921568627450981"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=1e8, dual=True)\n",
    "m.fit(trn_doc.sign(), y)\n",
    "preds = m.predict(val_doc.sign())\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9052287581699346"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=0.1, dual=True)\n",
    "m.fit(trn_doc, y)\n",
    "preds = m.predict(val_doc)\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9117647058823529"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=0.1, dual=True)\n",
    "m.fit(trn_doc.sign(), y)\n",
    "preds = m.predict(val_doc.sign())\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRI-GRAM MODEL DEPLOYMENT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_train.shape[0]\n",
    "vect = TfidfVectorizer(ngram_range=(1,4), tokenizer=tokenize,\n",
    "               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1 )\n",
    "trn_term_doc = vect.fit_transform(X_train)\n",
    "test_term_doc = vect.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_doc = trn_term_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_doc = test_term_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 49392)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_doc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['identity of the person',\n",
       " 'ideology',\n",
       " 'ideology his',\n",
       " 'ideology his horrific',\n",
       " 'ideology his horrific sick']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[20000:20005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y_train\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "        0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "        0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "        0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "        0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "        0, 1, 1, 0, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x49392 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 452484 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = trn_doc.sign()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<306x49392 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 59868 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x = val_doc.sign()\n",
    "val_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = x[y==1].sum(0)+1\n",
    "q = x[y==0].sum(0)+1\n",
    "r = np.log((p/p.sum())/(q/q.sum()))\n",
    "b = np.log(len(p)/len(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8758169934640523"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_preds = val_x @ r.T + b\n",
    "preds = pre_preds.T>0\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9150326797385621"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=0.1, dual=True)\n",
    "m.fit(x,y)\n",
    "preds = m.predict(val_x)\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 49392)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-2.41306, -1.04697, -1.85345, ...,  1.61229,  1.61229,  1.61229]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.08954, 0.351  , 0.1567 , ..., 5.01427, 5.01427, 5.01427]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spriyanshu723/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9150326797385621"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_nb = x.multiply(r)\n",
    "m = LogisticRegression(C=0.1, dual=True)\n",
    "m.fit(x_nb,y)\n",
    "\n",
    "val_x_nb = val_x.multiply(r)\n",
    "preds = m.predict(val_x_nb)\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
